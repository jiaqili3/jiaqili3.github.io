{"basics":{"name":"Yuancheng Wang","label":"Ph.D. Student at CUHK(SZ)","image":"","email":"yuanchengwang@link.cuhk.edu.cn","phone":"(+86) 189-5643-5965","url":"https://HeCheng0625.github.io/","summary":"A second-year Ph.D. student at CUHK(SZ), interested in text-to-speech synthesis, text-to-audio generation, and unified audio representation and generation.","location":{"city":"Shenzhen","countryCode":"CN","region":"Guangdong"}},"internship":[{"name":"Microsoft Research Asia","position":"Research Intern","location":"Beijing, China","startDate":"2022-12-01","endDate":"2023-06-01","summary":"Developed on audio generation & editing and larger scale text-to-speech synthesis.","highlights":["Audio Generation & Editing","Speech Synthesis"]},{"name":"ByteDance","position":"Research Intern","location":"Shenzhen, China","startDate":"2024-05-01","endDate":"","highlights":["Speech Understanding"]}],"volunteer":[{"organization":"IEEE Spoken Language Technology Workshop 2024","location":"Macau, China","position":"Student Volunteer","startDate":"2024-12-01","endDate":"2024-12-10"}],"education":[{"institution":"The Chinese University of Hong Kong, Shenzhen","location":"Shenzhen, China","area":"Computer Science, Artificial Intelligence, Speech","studyType":"PhD","startDate":"2023-09-01","endDate":""},{"institution":"The Chinese University of Hong Kong, Shenzhen","location":"Shenzhen, China","area":"Computer Science","studyType":"B.S.","startDate":"2019-09-01","endDate":"2023-06-01"},{"institution":"Hefei No.1 High School","location":"Hefei, Anhui, China","studyType":"High School","startDate":"2016-09-01","endDate":"2019-06-01"}],"awards":[{"title":"Duan Yongping Outstanding Resesearch Award","date":"2024"},{"title":"CUHK(SZ) The Bowen Scholarship","date":"2019 ~ 2023"},{"title":"First prize of Guangdong Province for the Mathematics competition of Chinese College Student","date":"2023"}],"publications":[{"name":"MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer","publisher":"ICLR 2025","releaseDate":"2025","url":"https://arxiv.org/abs/2409.00750","summary":"A fully non-autoregressive large-scale zero-shot TTS model eliminates the need for phone-level duration prediction."},{"name":"Naturalspeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models","publisher":"ICML 2024 Oral","releaseDate":"2024","url":"https://arxiv.org/abs/2403.03100","summary":"A large-scale zero-shot TTS model achieves on-par quality with human recordings."},{"name":"SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words","publisher":"NeurIPS 2024","releaseDate":"2024","url":"https://arxiv.org/abs/2406.13340","summary":"We propose a benchmark dataset to evaluate spoken dialogue understanding and generation."},{"name":"AUDIT: Audio Editing by following Instructions with Latent Diffusion Models","publisher":"NeurIPS 2023","releaseDate":"2023","url":"https://arxiv.org/abs/2304.00830","summary":"The first audio editing model that can follow natural language instructions."},{"name":"Amphion: an Open-Source Audio, Music, and Speech Generation Toolkit","publisher":"IEEE SLT 2024","releaseDate":"2024","url":"https://arxiv.org/abs/2312.09911","summary":"We develop a unified toolkit for audio, music, and speech generation."},{"name":"Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation","publisher":"IEEE SLT 2024","releaseDate":"2024","url":"https://arxiv.org/abs/2407.05361","summary":"We collect a 10w hours in-the-wild speech dataset for speech generation."}],"skills":[{"name":"Computer Science & AI","level":"Master","icon":"fa-solid fa-hashtag","keywords":["Python","PyTorch","Deep Learning","Generative Models"]}],"languages":[{"language":"Chinese","fluency":"Native speaker","icon":""},{"language":"English","fluency":"","icon":""}],"interests":[{"name":"Deep Learning","icon":"fa-solid fa-tag","keywords":["Generative Models","Speech Synthesis","Speech Language Models","Reinforcement Learning"]}]}